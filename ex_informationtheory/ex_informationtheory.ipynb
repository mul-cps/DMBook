{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a0d7a0",
   "metadata": {},
   "source": [
    "# Exercise - Information Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b05e025-9843-410e-80cd-f2db24148da8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "This is an exercise in understanding the concept of entropy and discretication  of analog signals based on Chapter 5 “Information Theory”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801c8f4-5a8e-439f-84f6-67bd420f05be",
   "metadata": {},
   "source": [
    "## Content <a id=\"sec_toc\"> </a> \n",
    "\n",
    "[Learning Objectives](#sec_0)\n",
    "\n",
    "[a) Entropy Calculation](#sec_a)\n",
    "\n",
    "[b) Signal Discretization and Reconstruction](#sec_b)\n",
    "\n",
    "[c) Entropy-based Signal Discretization](#sec_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be914d95-214f-473c-8fa2-7f0d25b34c8e",
   "metadata": {},
   "source": [
    "### <a id=\"sec_0\">Learning Objectives</a>\n",
    "\n",
    "* Understand and apply the concept of Shannon's information measure.\n",
    "* Explain and apply the concept of Shannon Entropy.\n",
    "* Intrepret the Nyquist-Shannon sampling theorem.\n",
    "* Apply entropy based signal dicretization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208862e-7b8b-435a-8ef5-4bbf09fe9feb",
   "metadata": {},
   "source": [
    "Import the needed libaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aec106-4955-4fbc-98e8-8e9109d126e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve\n",
    "from scipy.stats import entropy\n",
    "from ipywidgets import IntSlider, VBox\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9464c413",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0680df8-b815-41e4-92eb-3f6aebfb519d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "def get_entropy(string,symbols=None):\n",
    "    if symbols is None:\n",
    "        occur = dict(Counter(string.lower()))\n",
    "        o = occur\n",
    "    else: \n",
    "        occur = dict(Counter(char for char in string if char in symbols))\n",
    "        o = {symbol: occur.get(symbol, 0) for symbol in symbols}\n",
    "    H = 0\n",
    "    print(\"Orruencies of Symbols: \", o)\n",
    "    number_sym = sum(occur.values(),0)\n",
    "    for f in occur.values():\n",
    "        p = f/number_sym # len(string)\n",
    "        H -= p*math.log2(p)\n",
    "\n",
    "    _plot_entropy(string,symbols)\n",
    "    return H\n",
    "\n",
    "def _plot_entropy(string, symbols):\n",
    "    symbols_all = list(string.lower())\n",
    "    counts = Counter(symbols_all)\n",
    "    total = sum(counts.values())\n",
    "\n",
    "    symbols_unique = list(counts.keys())\n",
    "    p = np.array([counts[s] / total for s in symbols_unique])\n",
    "\n",
    "    base_color = \"#00727d\"      \n",
    "    highlight_color = \"#afd4d4\" \n",
    "\n",
    "    if symbols is None:\n",
    "        colors = [base_color] * len(symbols_unique)\n",
    "    else:\n",
    "        symbols = [s.lower() for s in symbols]\n",
    "        colors = [\n",
    "            highlight_color if s in symbols else base_color\n",
    "            for s in symbols_unique\n",
    "        ]\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(symbols_unique, p, color=colors, linewidth=1.5)\n",
    "    plt.xlabel(\"Symbol\")\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.title(\"Distribution of symbols within the sentence\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_value(x, name):\n",
    "    if x is None:\n",
    "        print(f\"{name} is still None. Please enter a valid value for {name}.\")\n",
    "        raise Exception(f\"Execution stopped because {name} is not defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c53ac1",
   "metadata": {},
   "source": [
    "##  <a id=\"sec_a\">a) Entropy Calculation</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e4116",
   "metadata": {},
   "source": [
    "The entropy measures the uncertainty or unpredictability of the data. In a dataset, it represents \\\n",
    "the minimum number of bits required to encode or represent the data without losing information.\n",
    "\n",
    "\n",
    "Formular of Entropy:  \n",
    "$$ H(X) = - \\sum_{i=1}^{n} p(x_i) \\cdot log_2 (p(x_i))$$\n",
    "\n",
    "$x_i$ ............. Specific / single outcome or symbol \\\n",
    "$p(x_i)$ ...... Probability of each outcome / symbol\n",
    "\n",
    "A higher entropy value indicates more uncertainty, which implies more data is required to represent the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a3b0e9",
   "metadata": {},
   "source": [
    "<u>TASK:</u> Choose a short sentence (string) and enter it where None is given.\n",
    "\n",
    "Notice, that all symbols, regardless if capital or small letters will be treated as small letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4c659",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\" # enter a sentence or some random letters & numbers\n",
    "\n",
    "## DO NOT CHANGE THE CODE BELOW\n",
    "# Method calculates the Entropy within a given sentence, either over given symbols or all symbols occuring\n",
    "check_value(sentence, \"sentence\")\n",
    "print(\"Your sentence: \\\"\",sentence,\"\\\"\")\n",
    "print(\"Set of all occuring Symbols: \",set(sentence.lower()))\n",
    "print(\"Calculated Entropy: \",get_entropy(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc1e4b",
   "metadata": {},
   "source": [
    "The Entropy above is calculated automatically "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e492258",
   "metadata": {},
   "source": [
    "<u>TASK:</u> Define your own reduced set of symbols (at least six) within the given List. Enter the symbol within the ' '. \\\n",
    "Note: You can also add symbols that do not occure in your sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of reduced symbols\n",
    "symbols = {\"\", \"\", \"\", \"\", \"\", \"\"} # DEFINE the reduced symbol set (at least six different symbols)\n",
    "\n",
    "## DO NOT CHANGE THE CODE BELOW\n",
    "check_value(sentence, \"sentence\")\n",
    "print(f\"Your sentence: \\\"{sentence}\\\"\")\n",
    "print(f\"Reduced set of Symbols: {symbols}\")\n",
    "print(f\"Reduced sentence: \\\"{''.join([char for char in sentence if char in symbols])}\\\" \")\n",
    "print(f\"Calculated Entropy: {get_entropy(sentence,symbols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0e8f4",
   "metadata": {},
   "source": [
    "[Back](#sec_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0194a",
   "metadata": {},
   "source": [
    "## <a id=\"sec_b\">b) Signal Discretization and Reconstruction</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156e177",
   "metadata": {},
   "source": [
    "The upcoming section explores the process of converting a continuous analog sine wave into \\\n",
    "its discrete representation through discretization. This involves sampling the sine wave at \\\n",
    "specific intervals, effectively capturing its essence in a digital format. Furthermore, the \\\n",
    "discrete signal is leveraged to reconstruct the original analog waveform, showcasing the relationship \\\n",
    "between the sampled data and the continuous signal it represents. This process highlights the \\\n",
    "fundamental principles of signal processing and the interplay between analog and digital domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9ab65-f9c8-4269-a6af-a52715c1190f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE\n",
    "def sample_signal(t):\n",
    "    x = (\n",
    "        1.0*np.sin(2*np.pi*5*t) +\n",
    "        0.6*np.sin(2*np.pi*30*t) +\n",
    "        0.3*np.sin(2*np.pi*80*t) +\n",
    "        0.25*np.sin(2*np.pi*130*t) \n",
    "    )\n",
    "    return x\n",
    "\n",
    "def plot_signal(t, x):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t, x)\n",
    "    plt.title(\"Analog Signal\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.xlim(0, 0.5)  # zoom in so structure is visible\n",
    "    plt.show()\n",
    "\n",
    "def plot_reconstruction(t_cont, t_samp, x_cont, x_samp, x_rec):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(t_cont, x_cont, label=\"Original continuous signal\")\n",
    "    plt.plot(t_samp, x_samp, 'o', label=\"Sampled points\")\n",
    "    plt.plot(t_cont, x_rec, '--', label=\"Reconstructed signal\")\n",
    "    plt.xlabel(\"Time [s]\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(f\"Original vs. Reconstructed Signal, Sampling Frequency = {fs} Hz\")\n",
    "    plt.xlim(0, 0.5) \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def sinc_reconstruct(t, t_samples, x_samples, fs):\n",
    "    #reconstruction using sinc interpolation\n",
    "    T = 1/fs\n",
    "    sinc_matrix = np.sinc((t[:, None] - t_samples[None, :]) / T)\n",
    "    return np.dot(sinc_matrix, x_samples)\n",
    "\n",
    "\n",
    "def check_value(x, x_name):\n",
    "    if x is None:\n",
    "        print(f\"{x_name} is still None. Please enter a valid value for {x_name}.\")\n",
    "        raise Exception(f\"Execution stopped because {x_name} is not defined.\")\n",
    "    \n",
    "def plot_reconstruction_interactive():\n",
    "    t_cont = np.linspace(0, 1, 5000)\n",
    "    x_cont = sample_signal(t_cont)\n",
    "    fs_init = 51\n",
    "    t_samp = np.linspace(0, 1, fs_init, endpoint=False)\n",
    "    x_samp = sample_signal(t_samp)\n",
    "    x_rec = sinc_reconstruct(t_cont, t_samp, x_samp, fs_init)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15,4))\n",
    "    line_cont, = ax.plot(t_cont, x_cont, label=\"Original continuous signal\")\n",
    "    line_rec, = ax.plot(t_cont, x_rec, '--', color='green', label=\"Reconstructed signal\")\n",
    "    scat = ax.scatter(t_samp, x_samp, marker='o', color='orange', label=\"Sampled points\")\n",
    "    ax.set_title(f\"Original vs. Reconstructed Signal, Sampling Frequency = {fs_init} Hz\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.legend()\n",
    "\n",
    "    fs_slider = IntSlider(value=fs_init, min=4, max=300, step=1,\n",
    "                          description='fs:', continuous_update=True,\n",
    "                          layout={'width':'800px'})\n",
    "\n",
    "\n",
    "    def update(change):\n",
    "        fs = change['new']\n",
    "        t_samp_new = np.linspace(0, 1, fs, endpoint=False)\n",
    "        x_samp_new = sample_signal(t_samp_new)\n",
    "        x_rec_new = sinc_reconstruct(t_cont, t_samp_new, x_samp_new, fs)\n",
    "\n",
    "        line_rec.set_ydata(x_rec_new)\n",
    "        scat.set_offsets(np.c_[t_samp_new, x_samp_new])\n",
    "        ax.set_title(f\"Sampling frequency fs = {fs}\")\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    fs_slider.observe(update, names='value')\n",
    "\n",
    "    display(VBox([fs_slider]))\n",
    "    return fig, ax, fs_slider  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6364b",
   "metadata": {},
   "source": [
    "Below is a Vizualization of the given analog signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE: Creating signal\n",
    "fs_cont = 5000\n",
    "t_cont = np.linspace(0, 1, fs_cont, endpoint=False)\n",
    "x_cont = sample_signal(t_cont)\n",
    "plot_signal(t_cont, x_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a85fd",
   "metadata": {},
   "source": [
    "The Nyquist-Shannon Theorem states that the sampling rate must be at least twice the \\\n",
    "highest frequency present in the signal to ensure accurate discretization. \n",
    "\n",
    "$fs > 2 * f_{max}$ \n",
    "\n",
    "Based on this principle, we now want to sample the signal at different sampling frequencies. \\\n",
    "The resulting plot visually compares the original analog signal with its sampled and reconstructed counterpart.\n",
    "\n",
    "To showcase the behaviour of the reconstruction using different sampling \\\n",
    "frequencies, we assume that the underlying frequencies are known.\n",
    "\n",
    "In this case, the signal contains the following frequencies:\n",
    "* 5 Hz\n",
    "* 30 Hz\n",
    "* 80 Hz\n",
    "* 130 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26171e7f",
   "metadata": {},
   "source": [
    "Underneath, the signal will be reconstructed using the sinc function. \n",
    "\n",
    "<u>TASK:</u> Explore different sample frequencies by changing the sampling frequency. What do you inspect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdddc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_interactive();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad96bb4-71b1-4edf-b6e6-2080293f50a3",
   "metadata": {},
   "source": [
    "[Back](#sec_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa791283",
   "metadata": {},
   "source": [
    "##  <a id=\"sec_c\">c) Entropy-based Signal Discretization</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9e044",
   "metadata": {},
   "source": [
    "Entropy and signal discretization are closely related concepts that can be effectively combined to\\\n",
    "improve signal processing. By applying entropy-based discretization, we can convert a continuous \\\n",
    "signal into a discrete one while preserving the most significant features and minimizing information \\\n",
    "loss. This method involves dividing the signal into a set of bins and assigning each value to the most \\\n",
    "appropriate bin, with the bin centers used for reconstruction. By linking entropy with discretization, \\\n",
    "we can optimize the representation of the signal, ensuring that the discretized version retains as much \\\n",
    "of the original information as possible, making it ideal for tasks like signal compression, reconstruction, \\\n",
    "and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5717f78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE: Overlapped analog signal\n",
    "class SignalProcessor:\n",
    "    def __init__(self, duration, sampling_rate):\n",
    "        self.duration = duration\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.time = np.linspace(0, duration, int(duration * sampling_rate), endpoint=False)\n",
    "\n",
    "    def sinusoidal(self, amplitude, frequency, delay):\n",
    "        \"\"\"Generates a sinusoidal signal.\"\"\"\n",
    "        return amplitude * np.sin(2 * np.pi * frequency * (self.time - delay))\n",
    "\n",
    "    def rectangular_pulse_train(self, peak, impulse_length, impulse_interval):\n",
    "        \"\"\"Generates a rectangular pulse train signal.\"\"\"\n",
    "        signal = np.zeros_like(self.time)\n",
    "        for start in np.arange(0, self.duration, impulse_interval):\n",
    "            end = start + impulse_length\n",
    "            signal[(self.time >= start) & (self.time < end)] = peak\n",
    "        return signal\n",
    "\n",
    "    def triangular_pulse_train(self, peak, impulse_length, impulse_interval):\n",
    "        \"\"\"Generates a triangular pulse train signal.\"\"\"\n",
    "        signal = np.zeros_like(self.time)\n",
    "        for start in np.arange(0, self.duration, impulse_interval):\n",
    "            end = start + impulse_length\n",
    "            mid = (start + end) / 2\n",
    "            for t in self.time[(self.time >= start) & (self.time < end)]:\n",
    "                if t <= mid:\n",
    "                    signal[np.isclose(self.time, t)] = peak * (t - start) / (mid - start)\n",
    "                else:\n",
    "                    signal[np.isclose(self.time, t)] = peak * (end - t) / (end - mid)\n",
    "        return signal\n",
    "\n",
    "    def sawtooth_pulse_train(self, peak, impulse_length, impulse_interval):\n",
    "        \"\"\"Generates a sawtooth pulse train signal.\"\"\"\n",
    "        signal = np.zeros_like(self.time)\n",
    "        for start in np.arange(0, self.duration, impulse_interval):\n",
    "            end = start + impulse_length\n",
    "            for t in self.time[(self.time >= start) & (self.time < end)]:\n",
    "                signal[np.isclose(self.time, t)] = peak * (t - start) / (end - start)\n",
    "        return signal\n",
    "\n",
    "    def half_sinusoidal_pulse_train(self, amplitude, frequency, impulse_interval):\n",
    "        \"\"\"Generates a half-sinusoidal pulse train signal.\"\"\"\n",
    "        signal = np.zeros_like(self.time)\n",
    "        for start in np.arange(0, self.duration, impulse_interval):\n",
    "            half_sinus = amplitude * np.sin(2 * np.pi * frequency * (self.time - start))\n",
    "            half_sinus = np.clip(half_sinus, 0, None)  # Keep only the positive half\n",
    "            signal += np.where((self.time >= start) & (self.time < start + 1/frequency), half_sinus, 0)\n",
    "        return signal\n",
    "\n",
    "    def compute_convolution(self, signal1, signal2):\n",
    "        \"\"\"Computes the convolution of two signals and normalizes the result.\"\"\"\n",
    "        conv = convolve(signal1, signal2, mode='full')\n",
    "        conv = conv[len(conv)//2 - len(self.time)//2 : len(conv)//2 + len(self.time)//2]  # Align time axis\n",
    "        conv /= np.max(np.abs(conv))  # Normalize the convolution result\n",
    "        return conv\n",
    "\n",
    "    def compute_elementwise_product(self, signal1, signal2):\n",
    "        \"\"\"Computes the element-wise product of two signals.\"\"\"\n",
    "        return signal1 * signal2\n",
    "\n",
    "    def entropy_based_discretization(self, signal, num_bins):\n",
    "        \"\"\"Performs entropy-based discretization of a signal.\"\"\"\n",
    "        # Define bin edges for discretization\n",
    "        bin_edges = np.linspace(np.min(signal), np.max(signal), num_bins + 1)\n",
    "        \n",
    "        # Digitize signal into bins\n",
    "        digitized = np.digitize(signal, bin_edges) - 1\n",
    "        digitized = np.clip(digitized, 0, num_bins - 1)  # Ensure indices are within valid range\n",
    "        # Reconstruct signal using bin centers\n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        reconstructed_signal = bin_centers[digitized]\n",
    "        # Compute probabilities for each bin\n",
    "        bin_counts = np.bincount(digitized, minlength=num_bins)\n",
    "        probabilities = bin_counts / len(signal)\n",
    "        # Compute entropy for the signal\n",
    "        signal_entropy = entropy(probabilities, base=2)\n",
    "        num_steps=self.count_signal_steps(reconstructed_signal)\n",
    "        return reconstructed_signal, signal_entropy, bin_edges, bin_counts, num_steps\n",
    "\n",
    "    def uniform_discretization(self, signal, step_size):\n",
    "        \"\"\"Performs classic uniform discretization of a signal.\"\"\"\n",
    "        indices = np.arange(0, len(signal), step_size)\n",
    "        sampled_values = signal[indices]\n",
    "        reconstructed_signal = np.zeros_like(signal)\n",
    "        for i in range(len(indices) - 1):\n",
    "            reconstructed_signal[indices[i]:indices[i+1]] = sampled_values[i]\n",
    "        reconstructed_signal[indices[-1]:] = sampled_values[-1]  # Fill the last section\n",
    "        return reconstructed_signal\n",
    "    \n",
    "    def get_time(self):\n",
    "        return self.time\n",
    "\n",
    "    def count_signal_steps(self,reconstructed_signal):\n",
    "        \"\"\"Zählt die Stufen im rekonstruierten Signal.\"\"\"\n",
    "        # Identifiziere Übergänge: wo sich der Wert im Signal ändert\n",
    "        step_changes = np.diff(reconstructed_signal) != 0\n",
    "        # Zähle die Anzahl der Änderungen und addiere die erste Stufe\n",
    "        num_steps = np.sum(step_changes) + 1  # +1 für die erste Stufe\n",
    "        return num_steps\n",
    "\n",
    "def plot_entropy_discretization(time, signal, reconstructed_signal, bin_edges, bin_counts):\n",
    "    \"\"\"\n",
    "    Plots the original signal with the bins and their counts as a bar plot, \n",
    "    with interactivity to toggle visibility of individual signals.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), gridspec_kw={\"width_ratios\": [3, 1]})\n",
    "\n",
    "    # Plot the original and reconstructed signals\n",
    "    ax1.axhline(0, color='black', lw=0.5, ls='-')\n",
    "    line1, = ax1.plot(time, signal, label=\"Original Signal\", alpha=0.7, color='orange')\n",
    "    line2, = ax1.plot(time, reconstructed_signal, label=\"Reconstructed Signal\", color='C0', linestyle=\"--\")\n",
    "    ax1.set_xlabel(\"Time [s]\")\n",
    "    ax1.set_ylabel(\"Amplitude [V]\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "\n",
    "    # Add bar plot of bin counts\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    ax2.barh(bin_centers, bin_counts, height=np.diff(bin_edges), color=\"green\", alpha=0.7, edgecolor=\"black\")\n",
    "    ax2.set_xlabel(\"Bin Counts\")\n",
    "    ax2.set_ylabel(\"Amplitude Range\")\n",
    "    ax2.set_title(\"Bin Count Distribution\")\n",
    "    ax2.grid(alpha=0.3)\n",
    "\n",
    "    plt.title(\"Entropy-based Discretization with Bin Counts\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "def calculate_mse(original_signal, reconstructed_signal):\n",
    "        \"\"\"Calculates the Mean Squared Error between two signals.\"\"\"\n",
    "        return np.mean((original_signal - reconstructed_signal) ** 2)\n",
    "\n",
    "def plot_signals(time, *signals, labels, colors, linestyles, title, duration):\n",
    "    \"\"\"Plots multiple signals.\"\"\"\n",
    "    create_plot(title, duration, 1.2)\n",
    "    for signal, label, color, ls in zip(signals, labels, colors, linestyles):\n",
    "        plt.plot(time, signal, label=label, color = color, linestyle=ls)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "def create_plot(title, duration = 1, ylim = 1):\n",
    "    \"\"\"\n",
    "    Creates/ Configures a plot (template) for visualizing a signal. (does not display it)\n",
    "\n",
    "    Parameters:\n",
    "    title: The title of the plot.\n",
    "    duration: The duration of the signal in seconds [s] to be displayed on the x-axis.\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Amplitude [V]')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.ylim(-ylim, ylim)\n",
    "    plt.xlim(0, math.floor(duration))\n",
    "    plt.axhline(0, color='black', lw=0.5, ls='-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6b8f6b",
   "metadata": {},
   "source": [
    "The next code section generates a combined signal by superimposing multiple signal types, such \\\n",
    "as sinusoidal waves, rectangular pulses, or triangular pulses, to create a complex waveform for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13622c4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE: Generating combined signal\n",
    "\n",
    "dur = 200  # [s]\n",
    "sampling_rate = 200  # [Hz]\n",
    "sp = SignalProcessor(dur, sampling_rate)\n",
    "# Create seperate part-signals\n",
    "sinus = sp.sinusoidal(amplitude=1, frequency=0.2, delay=0.5)\n",
    "rect_pulse = sp.rectangular_pulse_train(peak=1, impulse_length=50, impulse_interval=100)\n",
    "tri_pulse = sp.triangular_pulse_train(peak=1, impulse_length=50, impulse_interval=100)\n",
    "saw_pulse = sp.sawtooth_pulse_train(peak=1, impulse_length=50, impulse_interval=100)\n",
    "sine_pulse = sp.half_sinusoidal_pulse_train(amplitude=1, frequency=0.01, impulse_interval=100)\n",
    "# Combine signals\n",
    "elementwise_product = sp.compute_elementwise_product(sinus, sine_pulse)\n",
    "\n",
    "# Plot original signal\n",
    "create_plot(\"Non-uniform / superimposed analog signal\", dur, 1.3)\n",
    "plt.plot(sp.get_time(), elementwise_product, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7569bc4",
   "metadata": {},
   "source": [
    "The following code section performs entropy-based discretization and reconstruction of a signal. It \\\n",
    "divides the signal into bins based on entropy optimization, assigns discrete values, and reconstructs \\\n",
    "the signal using the bin centers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63373ca",
   "metadata": {},
   "source": [
    "<u>TASK:</u> Change the number of bins used for the discritization based on the entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea67a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_number = None # CHANGE the bin number in a range between (2,20)\n",
    "\n",
    "# DO NOT CHANGE THE CODE BELOW\n",
    "check_value(bin_number,\"bin_number\")\n",
    "# Perform entropy-based discretization\n",
    "reconstructed_entropy_signal, signal_entropy, bin_edges, bin_counts, num_entropy_steps = sp.entropy_based_discretization(elementwise_product, num_bins=bin_number)\n",
    "print(f\"Signal Entropy: {signal_entropy}\")\n",
    "\n",
    "# Plot the entropy-based discretization\n",
    "plot_entropy_discretization(sp.get_time(),elementwise_product, reconstructed_entropy_signal, bin_edges, bin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841ef37b",
   "metadata": {},
   "source": [
    "The next code section compares uniform discretization with entropy-based discretization, ensuring that both reconstructed signals have the same number of \"steps\" (distinct levels). This allows for a fair evaluation of the methods' performance and reconstruction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc96e303",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE: Compare reconstructions\n",
    "\n",
    "step_size = round((num_entropy_steps/19902)**(1/-1)) # Power function as a relationship between num_uniform_steps and step_size\n",
    "\n",
    "# Perform uniform discretization\n",
    "reconstructed_uniform_signal = sp.uniform_discretization(elementwise_product, step_size=step_size)\n",
    "# Plot the original and reconstructed signals\n",
    "plot_signals(sp.get_time(),elementwise_product, reconstructed_entropy_signal, reconstructed_uniform_signal, labels=['Original Signal', 'Entropy-based Reconstruction', 'Uniform Reconstruction'], colors=[\"orange\",\"C0\",\"brown\"], linestyles=[\"-\",\"-\",\"-\"], title = \"Uniform vs. Entropy-based discritization\", duration = dur)\n",
    "# Plot the original and reconstructed signals\n",
    "plot_signals(sp.get_time(),elementwise_product, reconstructed_entropy_signal, reconstructed_uniform_signal, labels=['Original Signal', 'Entropy-based Reconstruction', 'Uniform Reconstruction'], colors=[\"orange\",\"C0\",\"brown\"], linestyles=[\"-\",\"-\",\"-\"], title = \"Uniform vs. Entropy-based discritization (Zoomed)\", duration = dur/2-30)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_entropy = calculate_mse(elementwise_product, reconstructed_entropy_signal)\n",
    "mse_uniform = calculate_mse(elementwise_product, reconstructed_uniform_signal)\n",
    "print(f\"MSE (Entropy-based): {mse_entropy} V²\")\n",
    "print(f\"MSE (Uniform): {mse_uniform} V²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1a232",
   "metadata": {},
   "source": [
    "[Back](#sec_toc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
